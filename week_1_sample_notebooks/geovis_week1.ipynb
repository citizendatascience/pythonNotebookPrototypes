{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1\n",
    "## Notebook 2: Geospatial Visualisation and Further Exploration of Dataframes\n",
    "\n",
    "### Our dataset\n",
    "This dataset is based on citizen's reports to FixMyStreet.com regarding problems with pavements or potholes.For each report there is a category assigned, the longitude and the latitude are provided, as well as some datazone information (name of the datazone and code).\n",
    "\n",
    "### Aims\n",
    "1. Reinforce some of the concepts covered earlier\n",
    "2. Introduce and learn how to apply further dataframes manipulation techniques \n",
    "3. Learn how to use gmplot to create geospatial visualisations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gmplot\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall: Reading from a csv\n",
    "In the previous notebook, we learned how to read from a csv file and create a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(\"fix_myStreetGlasgow.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task\n",
    "\n",
    "1. What are the columns of the dataframe? \n",
    "2. Get the last 10 elements of the dataframe\n",
    "3. What are the minimum and maximum latitude and longitude?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the columns of the dataframe\n",
    "print (dataframe.ATTRIBUTE)\n",
    "\n",
    "#last 10 elements\n",
    "print (dataframe.FUNCTION)\n",
    "\n",
    "#min and max longitude/latitude\n",
    "print (str(dataframe['COLUMN_NAME'].FUNCTION + ' is the min')\n",
    "print (str(dataframe['COLUMN_NAME'].FUNCTION) + ' is the max')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output\n",
    "columns: Index(['category', 'latitude', 'longitude', 'datazone', 'name'], dtype='object')\n",
    "\n",
    "last 10 elements: \n",
    "\n",
    "\n",
    " |category | latitude|longitude|datazone|name| \n",
    "|:-------|:--------|:--------|:--------|:---|\n",
    "|Potholes| 55.81172|  -4.33927 | S01009782| Nitshill - 08  |\n",
    "|Pavements/footpaths|  55.84243|   -4.27378|  S01009881 | Pollokshields East - 01|\n",
    "| Potholes | 55.87842 | -4.27847|  S01010307| Firhill - 07|  \n",
    "|Potholes|  55.86728 |  -4.23603|  S01010262| City Centre East - 04   |\n",
    "|Potholes|  55.88295 |  -4.30497 | S01010412 |Kelvinside and Jordanhill - 05  |\n",
    "|Pavements/footpaths | 55.85108 |  -4.32594 | S01009851 |Craigton - 04  |\n",
    "|Pavements/footpaths | 55.84770 | -4.22407  |S01010053 |Parkhead West and Barrowfield - 05  |                 \n",
    "|Pavements/footpaths | 55.83499 |  -4.36386 | S01009804   |Pollok North and East - 06  |\n",
    "|Pavements/footpaths | 55.87559 |  -4.13677 | S01010117  | Garthamlock, Auchinlea and Gartloch - 05  |\n",
    "|Pavements/footpaths | 55.83467 |  -4.26067 | S01009888 | Govanhill West - 02|  \n",
    "\n",
    "Min and max latitude: <br>\n",
    "Max latitude: 55.926809999999996\n",
    "Min latitude: 55.784009999999995\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising Our Data\n",
    "\n",
    "We have a list of potholes and pavements problems and it would be quite useful to see where those are and which areas it would be a good idea to avoid because of their bad road conditions. Here you will be introduced to using gmplot to visualise geographical data. You provide gmplot with longitude and latitude, then based on Google Maps gmplot plots the coordinates and stores an hmtl file with a geographical heatmap in your workspace. \n",
    "\n",
    "### What's a heatmap? \n",
    "Heatmaps use colour-coding to present different values. In our particular case, if we see a lot of red on the map that means there are many road problems in a particular area of Glasgow. \n",
    "\n",
    "Heatmaps can be applied to a different range of domains such as: #TODO\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the latitudes and longitudes\n",
    "latitudes = dataframe[\"latitude\"]\n",
    "longitudes = dataframe[\"longitude\"]\n",
    "\n",
    "# Creating the location we would like to initialize the focus on. \n",
    "# Parameters: Lattitude, Longitude, Zoom\n",
    "gmap = gmplot.GoogleMapPlotter(55.8721,-4.2882,10)\n",
    "\n",
    "# Overlay our datapoints onto the map\n",
    "gmap.heatmap(latitudes, longitudes)\n",
    "\n",
    "# Generate the heatmap into an HTML file\n",
    "gmap.draw(\"Glasgow_heatmap.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering\n",
    "\n",
    "It was great to see our potholes visualised but sometimes we want to have our data quantified. Currently, we have a single record per pothole per regoion but it would be nice to get a summary of the problems per datazone. \n",
    "\n",
    "Essentially, what we want to achieve is having the results in the following form:\n",
    "\n",
    "| name | potholes | \n",
    "|:-------|:--------|\n",
    "| Alexandra Parade - 03 | 3 |\n",
    "| Anderston - 01        | 7 |\n",
    "| ...                   | ... |\n",
    "\n",
    "The next few cells will cover the following concepts: \n",
    "1. filtering based on a value\n",
    "2. grouping by a column to obtain a statistic\n",
    "3. creating a new dataframe\n",
    "\n",
    "\n",
    "NOTE: While there is a method called filter in pandas, we are not going to use it as part of this exercise as it only allows us to filter on the specified index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns only the rows for which the category is potholes\n",
    "#print (dataframe['category']=='Potholes')\n",
    "#the result we get is the column of the dataframe with true/false values signifying whether the entry is a pothole or not.\n",
    "#What we want next is based on those values to pull only the true value entry and pandas do that for us\n",
    "dataF = dataframe[dataframe['category'] == 'Potholes']\n",
    "\n",
    "#Printing dataF to see that we are only left with only entries classified as potholes\n",
    "#print (dataF)\n",
    "\n",
    "#once we have only the potholes, we want to aggregate the results based on the name of the datazone and count the total number of potholes\n",
    "dataF = dataF.groupby('name', as_index=False)\n",
    "\n",
    "for name in dataF: \n",
    "    print (name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Datazone  Potholes\n",
      "0  Alexandra Parade - 03         3\n",
      "1         Anderston - 01         7\n",
      "2         Anderston - 02         9\n",
      "3         Anderston - 03         1\n",
      "4         Anderston - 04         2\n",
      "5         Anderston - 05        10\n",
      "6         Anderston - 06         6\n",
      "7   Anniesland East - 01         4\n",
      "8   Anniesland East - 02         9\n",
      "9   Anniesland East - 03         3\n"
     ]
    }
   ],
   "source": [
    "#So far: only potholes in our data, grouped-by the datazone where they were reported.\n",
    "\n",
    "#Next goal: count the potholes/pavement issues in the same zone\n",
    "\n",
    "dataF = dataF['category'].count()\n",
    "\n",
    "#Now when we have that, we would lile to store it in a new dataframe \n",
    "\n",
    "dataPo = pd.DataFrame(data=dataF).rename(index=str, columns={\"name\": \"Datazone\", \"category\": \"Potholes\"})\n",
    "\n",
    "print (dataPo.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task\n",
    "Now when you know how filtering work, please complete the following exercises: \n",
    "1. What are the datazones with more than 13 potholes? \n",
    "2. What's the maximum number of potholes recorded? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataPo13 dataframe to store the entries with more than 13 potholes. You may find > helpful.Recall how we applied filtering condition earlier. \n",
    "#HINT: the dataframe we base our analysis on is dataPo13\n",
    "dataPo13 = DATAFRAME_NAME[DATAFRAME_NAME['Potholes']>13]\n",
    "print (dataPo13)\n",
    "\n",
    "#based on dataPo dataframe identify max number of potholes recorded\n",
    "maxPotholes = dataPo[column_name].FUNCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task\n",
    "\n",
    "Based on the earlier example, create a dataframe, called **dataPav** that contains the datazones and the count of pavements/footpath issues. Follow the steps outlined below if you are stuck: \n",
    "\n",
    "1. Filter the data based on whether the value of the 'category' is 'Pavements/footpaths'\n",
    "2. Group it by 'name' and count the total occurences per datazone\n",
    "3. Create a new dataframe, called **dataPav**, with columns: 'Datazone' and 'Pavements'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2185\n"
     ]
    }
   ],
   "source": [
    "#returns only the rows for which the category is pavements. HINT: Check whether you got the correct field name\n",
    "dataPav = dataframe[dataframe['category'] == \"Pavements/footpaths\"]\n",
    "\n",
    "#check the size of your dataframe; your result should be 2185 entries\n",
    "print (dataPav.size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same as above\n",
    "dataPav = dataPav.groupby('name', as_index=False)['category'].count()\n",
    "\n",
    "#creat \n",
    "dataPav = pd.DataFrame(data=dataPav).rename( columns={\"name\": \"Datazone\", \"category\": COLUMN_NAME})\n",
    "\n",
    "print (dataPav.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating dataframes\n",
    "\n",
    "Assuming your code for the previous task works, now you should have 2 dataframes: \n",
    "\n",
    "1. dataPo: containing 2 columns, the name of the datazone and the count of potholes for that datazone\n",
    "2. dataPav: containing 2 columns, the name of the datazone and the count of reported pavement problems\n",
    "\n",
    "Ideally, what we want to do is to have one dataframe that combines the data from dataPo and dataPav. Since the column 'Datazone' is common for the two dataframes, we want to use it to join them together.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenating the two dataframes\n",
    "result = pd.merge(dataPo,dataPav, how='outer')\n",
    "print (result.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output\n",
    "\n",
    "| Datazone | Potholes|Pavements| \n",
    "|:-------|:--------|:--------|\n",
    "| Alexandra Parade - 03 | 3 .0|NaN|\n",
    "| Anderston - 01   |    7.0    |   1.0|\n",
    "|Anderston - 02    |   9.0     |   NaN|\n",
    "|Anderston - 03    |   1.0     |   NaN|\n",
    "|Anderston - 04    |   2.0     |   NaN|\n",
    "|Anderston - 05    | 10.0      |  1.0|\n",
    "|Anderston - 06    |  6.0      |  2.0|\n",
    "|Anniesland East - 01|4.0|   NaN|\n",
    "|Anniesland East - 02|9.0|   2.0|\n",
    "|Anniesland East - 03|3.0|   NaN|  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Side Note\n",
    "What happens when you print the resulting dataframe? \n",
    "\n",
    "Sometimes the count value is **NaN**.\n",
    "\n",
    "Why? Since no problems have been reported for this area. Maybe there are no road problems for those datazones or maybe they haven't been reported. In a few words, we don't know, and therefore we have **missing data**.\n",
    "\n",
    "There are different techniques for dealing with missing data and they will be discussed later but for now we choose to replace all missing values with 0, as we can make the assumption that there are no road problems. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.fillna(0)\n",
    "print (result.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected Output\n",
    "\n",
    " | Datazone | Potholes|Pavements| \n",
    "|:-------|:--------|:--------|\n",
    "| Alexandra Parade - 03 | 3 .0|0.0|\n",
    "| Anderston - 01   |    7.0    |   1.0|\n",
    "|Anderston - 02    |   9.0     |   0.0|\n",
    "|Anderston - 03    |   1.0     |   0.0|\n",
    "|Anderston - 04    |   2.0     |   0.0|\n",
    "|Anderston - 05    | 10.0      |  1.0|\n",
    "|Anderston - 06    |  6.0      |  2.0|\n",
    "|Anniesland East - 01|4.0|   0.0|\n",
    "|Anniesland East - 02|9.0|   2.0|\n",
    "|Anniesland East - 03|3.0|   0.0|  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
