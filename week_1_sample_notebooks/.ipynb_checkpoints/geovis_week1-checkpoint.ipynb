{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1\n",
    "## Notebook 2: Geospatial Visualisation and Further Exploration of Dataframes\n",
    "\n",
    "### Our dataset\n",
    "This dataset is based on citizen's reports to FixMyStreet.com regarding problems with pavements or potholes.For each report there is a category assigned, the longitude and the latitude are provided, as well as some datazone information (name of the datazone and code).\n",
    "\n",
    "### Aims\n",
    "1. Reinforce some of the concepts covered earlier\n",
    "2. Introduce and learn how to apply further dataframes manipulation techniques \n",
    "3. Learn how to use gmplot to create geospatial visualisations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gmplot\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall: Reading from a csv\n",
    "In the previous notebook, we learned how to read from a csv file and create a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(\"fix_myStreetGlasgow.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task\n",
    "\n",
    "1. What are the columns of the dataframe? \n",
    "2. Get the last 10 elements of the dataframe\n",
    "3. What are the minimum and maximum latitude and longitude?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#print the columns of the dataframe\n",
    "print ()\n",
    "\n",
    "#last 10 elements\n",
    "#print (dataframe.FUNCTION)\n",
    "\n",
    "#min and max longitude/latitude\n",
    "#print (dataframe[columnKey].FUNCTION + ' is the min')\n",
    "#print (dataframe[columnKey].FUNCTION + ' is the max')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising Our Data\n",
    "\n",
    "We have a list of potholes and pavements problems and it would be quite useful to see where those are and which areas it would be a good idea to avoid because of their bad road conditions. Here you will be introduced to using gmplot to visualise geographical data. You provide gmplot with longitude and latitude, then based on Google Maps gmplot plots the coordinates and stores an hmtl file with a geographical heatmap in your workspace. \n",
    "\n",
    "### What's a heatmap? \n",
    "Heatmaps use colour-coding to present different values. In our particular case, if we see a lot of red on the map that means there are many road problems in a particular area of Glasgow. \n",
    "\n",
    "Heatmaps can be applied to a different range of domains such as: #TODO\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataframe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-e0b7052908bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# take the latitudes and longitudes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlatitudes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"latitude\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mlongitudes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"longitude\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Creating the location we would like to initialize the focus on.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataframe' is not defined"
     ]
    }
   ],
   "source": [
    "# take the latitudes and longitudes\n",
    "latitudes = dataframe[\"latitude\"]\n",
    "longitudes = dataframe[\"longitude\"]\n",
    "\n",
    "# Creating the location we would like to initialize the focus on. \n",
    "# Parameters: Lattitude, Longitude, Zoom\n",
    "gmap = gmplot.GoogleMapPlotter(55.8721,-4.2882,10)\n",
    "\n",
    "# Overlay our datapoints onto the map\n",
    "gmap.heatmap(latitudes, longitudes)\n",
    "\n",
    "# Generate the heatmap into an HTML file\n",
    "gmap.draw(\"Glasgow_heatmap.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering\n",
    "\n",
    "Based on the data we have it would be nice to quantify the potholes and pavements issues per datazone. In this way we should be able to identify which areas are most problematic. \n",
    "\n",
    "Essentially, what we want to achieve is having the results in the following form:\n",
    "\n",
    "| name | potholes | \n",
    "|:-------|:--------|\n",
    "| Alexandra Parade - 03 | 3 |\n",
    "| Anderston - 01        | 7 |\n",
    "| ...                   | ... |\n",
    "\n",
    "The next few cells will cover the following concepts: \n",
    "1. filtering based on a value\n",
    "2. grouping by a column to obtain a statistic\n",
    "3. creating a new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Datazone  Potholes\n",
      "0  Alexandra Parade - 03         3\n",
      "1         Anderston - 01         7\n",
      "2         Anderston - 02         9\n",
      "3         Anderston - 03         1\n",
      "4         Anderston - 04         2\n",
      "5         Anderston - 05        10\n",
      "6         Anderston - 06         6\n",
      "7   Anniesland East - 01         4\n",
      "8   Anniesland East - 02         9\n",
      "9   Anniesland East - 03         3\n"
     ]
    }
   ],
   "source": [
    "#returns only the rows for which the category is potholes\n",
    "dataF = dataframe[dataframe['category'] == 'Potholes']\n",
    "\n",
    "\n",
    "#once we have only the potholes, we want to aggregate the results based on the name of the datazone and count the total number of potholes\n",
    "dataF = dataF.groupby('name', as_index=False)['category'].count()\n",
    "\n",
    "#Now when we have that, we would lile to store it in a new dataframe\n",
    "dataPo = pd.DataFrame(data=dataF).rename(index=str, columns={\"name\": \"Datazone\", \"category\": \"Potholes\"})\n",
    "\n",
    "print (dataPo.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task\n",
    "Now when you know how filtering work, please complete the following exercises: \n",
    "1. What are the datazones with more than 13 potholes? \n",
    "2. What's the maximum number of potholes recorded? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataPo13 dataframe to store the entries with more than 13 potholes\n",
    "dataPo13 = \n",
    "print (dataPo13)\n",
    "\n",
    "#based on dataPo dataframe identify max number of potholes recorded\n",
    "maxPotholes = dataPo[column_name].FUNCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task\n",
    "\n",
    "Based on the earlier example, create a dataframe, called **dataPav** that contains the datazones and the count of pavements/footpath issues. Follow the steps outlined below if you are stuck: \n",
    "\n",
    "1. Filter the data based on whether the value of the 'category' is 'Pavements/footpaths'\n",
    "2. Group it by 'name' and count the total occurences per datazone\n",
    "3. Create a new dataframe, called **dataPav**, with columns: 'Datazone' and 'Pavements'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2185\n"
     ]
    }
   ],
   "source": [
    "#returns only the rows for which the category is pavements. HINT: Check whether you got the correct field name\n",
    "dataPav = dataframe[dataframe['category'] == CONDITION]\n",
    "\n",
    "#check the size of your dataframe; your result should be 2185 entries\n",
    "print (dataPav.size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Datazone  Pavements\n",
      "0         Anderston - 01          1\n",
      "1         Anderston - 05          1\n",
      "2         Anderston - 06          2\n",
      "3   Anniesland East - 02          2\n",
      "4   Anniesland East - 05          2\n",
      "5   Anniesland West - 03          1\n",
      "6   Anniesland West - 04          2\n",
      "7   Anniesland West - 06          1\n",
      "8   Anniesland West - 08          2\n",
      "9  Baillieston East - 01          1\n"
     ]
    }
   ],
   "source": [
    "#same as above\n",
    "dataPav = dataPav.FUNCTION_NAME('name', as_index=False)['category'].count()\n",
    "\n",
    "#creat \n",
    "dataPav = pd.DataFrame(data=dataPav).rename( columns={\"name\": \"Datazone\", \"category\": COLUMN_NAME})\n",
    "\n",
    "print (dataPav.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating dataframes\n",
    "\n",
    "Assuming your code for the previous task works, now you should have 2 dataframes: \n",
    "\n",
    "1. dataPO: containing 2 columns, the name of the datazone and the count of potholes for that datazone\n",
    "2. dataPav: containing 2 columns, the name of the datazone and the count of reported pavement problems\n",
    "\n",
    "Ideally, what we want to do is to have one dataframe that combines the data from dataPo and dataPav. Since the column 'Datazone' is common for the two dataframes, we want to use it to join them together.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Datazone  Potholes  Pavements\n",
      "0  Alexandra Parade - 03       3.0        NaN\n",
      "1         Anderston - 01       7.0        1.0\n",
      "2         Anderston - 02       9.0        NaN\n",
      "3         Anderston - 03       1.0        NaN\n",
      "4         Anderston - 04       2.0        NaN\n",
      "5         Anderston - 05      10.0        1.0\n",
      "6         Anderston - 06       6.0        2.0\n",
      "7   Anniesland East - 01       4.0        NaN\n",
      "8   Anniesland East - 02       9.0        2.0\n",
      "9   Anniesland East - 03       3.0        NaN\n"
     ]
    }
   ],
   "source": [
    "#concatenating the two dataframes\n",
    "result = pd.merge(dataPo,dataPav, how='outer')\n",
    "print (result.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output\n",
    "\n",
    "| Datazone | Potholes|Pavements| \n",
    "|:-------|:--------|:--------|\n",
    "| Alexandra Parade - 03 | 3 .0|NaN|\n",
    "| Anderston - 01   |    7.0    |   1.0|\n",
    "|Anderston - 02    |   9.0     |   NaN|\n",
    "|Anderston - 03    |   1.0     |   NaN|\n",
    "|Anderston - 04    |   2.0     |   NaN|\n",
    "|Anderston - 05    | 10.0      |  1.0|\n",
    "|Anderston - 06    |  6.0      |  2.0|\n",
    "|Anniesland East - 01|4.0|   NaN|\n",
    "|Anniesland East - 02|9.0|   2.0|\n",
    "|Anniesland East - 03|3.0|   NaN|  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Side Note\n",
    "What happens when you print the resulting dataframe? \n",
    "\n",
    "Sometimes the count value is **NaN** since no problems have been reported for this area. In similar cases, we say we have **missing data**. There are different techniques for dealing with missing data but before we discuss this any further, we can just replace all 'NaN's with 0s instead. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Datazone  Potholes  Pavements\n",
      "0  Alexandra Parade - 03       3.0        0.0\n",
      "1         Anderston - 01       7.0        1.0\n",
      "2         Anderston - 02       9.0        0.0\n",
      "3         Anderston - 03       1.0        0.0\n",
      "4         Anderston - 04       2.0        0.0\n",
      "5         Anderston - 05      10.0        1.0\n",
      "6         Anderston - 06       6.0        2.0\n",
      "7   Anniesland East - 01       4.0        0.0\n",
      "8   Anniesland East - 02       9.0        2.0\n",
      "9   Anniesland East - 03       3.0        0.0\n"
     ]
    }
   ],
   "source": [
    "result = result.fillna(0)\n",
    "print (result.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output\n",
    "\n",
    " | Datazone | Potholes|Pavements| \n",
    "|:-------|:--------|:--------|\n",
    "| Alexandra Parade - 03 | 3 .0|0.0|\n",
    "| Anderston - 01   |    7.0    |   1.0|\n",
    "|Anderston - 02    |   9.0     |   0.0|\n",
    "|Anderston - 03    |   1.0     |   0.0|\n",
    "|Anderston - 04    |   2.0     |   0.0|\n",
    "|Anderston - 05    | 10.0      |  1.0|\n",
    "|Anderston - 06    |  6.0      |  2.0|\n",
    "|Anniesland East - 01|4.0|   0.0|\n",
    "|Anniesland East - 02|9.0|   2.0|\n",
    "|Anniesland East - 03|3.0|   0.0|  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
